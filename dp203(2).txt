101. 2-3 > 4-2
• Polybase 옵션은 대상이 Synapse인 경우에만 사용할 수 있음
• Polybase가 Bulk Insert보다 빠름

102. 2-4 ***

103. B
• 데이터 엔지니어와 작업을 위한 높은 동시성 클러스터가 필요함

104. C
일정 트리거가 있는 상위 파이프라인이어야 함
• 상위 파이프라인에는 4개의 파이프라인 실행 활동이 있음
☞ Ingest1과 Ingest2에는 종속성이 없고, 차원 파이프라인에는 수집1/수집2 파이프라인 모두의 '완료시' 출력에서 두가지 종속성이 존재하여 팩트 파이프라인에는 차원 파이프라인에 대한 하나의 '완료시' 종속성 존재

105. 2-1-5 > 1-3-5
1) 마스터키는 데이터베이스에서 한번만 생성되어야함
☞ 마스터키는 데이터베이스에서 인증서의 개인키와 비대칭키를 보호하는데 사용되는 대칭키
2) 데이터베이스 범위 자격 증명은 외부 리소스를 연결하는데 필요한 인증 정보가 포함된 레코드로, 데이터베이스 범위 자격증명을 만들기 전에 먼저 마스터키를 만들어야함
3) 외부데이터 원본은 Polybase를 사용하여 데이터 로드를 위한 연결을 설정하는데 사용됨
106. D
워터마크 지연은 스트리밍 데이터 처리 작업의 지연을 나타냄
• 스트리밍 파이프라인의 속도를 늦출 수 있는 리소스 제약 조건
☞ Stream Analytics의 처리 리소스가 입력 이벤트의 볼륨을 처리하기에 충분하지 않을 때
☞ 입력 이벤트 브로커 내에서 처리량이 충분하지 않아 조절될 때
☞ 출력 싱크에 용량이 충분하지 않아 제한됨

107. 3-3 > 4-3
1) TopOne은 최상위 레코드를 반환하는데 여기서 rank는 지정된 순에 따라 창에서 이벤트의 순위 위치를 정의함. 순서/순위는 이벤트 열을 기준으로 하며 ORDER BY절에서 지정할 수 있음
2) Hoping window의 구문에는 3개의 인수가 필요하여 정확히 동일한 요구 사항을 충족하려면 Tumbling 창이 더 알맞음

108. B
• 저장 프로시저 활동을 사용하여 R 스크립트를 실행할 수 없음

109. B
• 작업에 높은 동시성 클러스터가 필요로함

110. B ?? C ??
• 높은 동시성 클러스터는 관리되는 클라우드 리소스로 주요 이점은 리소스 활용도를 최대화하고 쿼리 대기 시간을 최소화하기 위해 세분화된 공유를 제공한다는 것임
• Databricks는 작업을 실행하는데 필요한 적절한 수의 작업자를 선택하는데 이를 자동 크기조정이라고 함
☞ 자동 크기 조정을 사용하면 워크로드에 맞게 클러스터를 프로비저닝할 필요가 없기 때문에 높은 클러스터 활용도를 더 쉽게 달성할 수 있음

111. 4-4-3 > 4-4-3
1) 해당 출력은 텀블링 창 트리거에서 나온것이며 /{HH}/ 수준에서 올바른 디렉터리를 식별하는데 필요함
2) 각 장치 유형에 대한 시간별 데이터 세트를 얻기 위한 지정 패턴
3) 이름 지정 패턴이 ‘deviceID’로 시작하기 때문에 각 장치 유형에 대한 여러 파일이 소스 측에 존재하므로 파일을 싱크에서 병합하여 장치 유형당 단일 파일을 생성해야함

112. 4-6-1 > 8-6-1
1) 날짜 형식은 선택사항으로 날짜 토큰이 접두사 경로에 사용되는 경우 파일이 구성되는 날짜 형식을 선택할 수 있고, 시간 형식도 선택사항으로 시간 토큰이 접두사 경로에 사용되는 경우 파일이 구성되는 시간형식을 지정
2) 각 지역의 데이터 엔지니어는 해당 지역의 데이터에 대해서만 자체 파이프라인을 구축할 수 있어야함

113. 1-2 > 2-3
1) LAG 기능을 필터로 사용하여 'HeartBeat'에서 오류로 전환하거나 오류에서 'HeartBeat'로 전환하는 이벤트만 걸러냄
2) 오류가 있더라도 장치는 항상 5분마다 메시지를 보내고 여기에 어떤 창이 필요하지 않은 결함 사이의 가동 시간을 계산함

114. A
• DataBricks 셸의 언어를 Scala,SQL,Python 또는 R로 변경하려면 셸 앞에 %~를 접두사로 붙이고 그 뒤에 언어를 붙임

115. D
• 파이프라인 오루가 발생한 경우 텀블링 창 트리거는 사용자 개입 없이 동일한 입력 매개변수를 사용하여 참조된 파이프라인의 실행을 자동으로 재시도 할 수 있음

116. A,C **
필터링을 사용하여 일별 파일만 복사

117. A > C
• 추가모드는 마지막 트리거 이후 결과 테이블에 추가된 새 행만 외부 저장소에 기록되고 이는 결과 테이블의 기존 행이 변경되지 않을 것으로 예상되는 쿼리에만 적용됨.
A : 업데이트 모드는 마지막 트리거 이후 결과 테이블에서 업데이트된 행만 외부 저장소에 기록되고 마지막 트리거 이후 변경된 행만 출력한다는 점에서 완료 모드와 다르고 쿼리에 집계가 포함되어 있지 않으면 추가 모드와 동일함
B : 완료모드는 업데이트된 전체 결과 테이블이 외부 저장소에 기록되고 전체 테이블의 쓰기를 처리하는 방법을 결정하는 것은 스토리지 커넥터에 달려 있음

118. A
• 파생 열 변환을 사용하여 데이터 흐름에서 새 열을 생성하거나 기존 필드를 수정할 수 있음
119. B
• 외부 테이블은 소스 플랫 파일 구조를 기반으로 하고 이러한 테이블에 날짜 시간 열을 추가하는 것은 의미가 없음
120. B
• 서버리스 풀을 사용하여 전용 풀에 테이블을 생성할 수 없음
121, B
122. B

123. B
124. B

125. D
• 평면화 변환을 사용하여 JSON과 같은 계층 구조 내에서 배열 값을 가져와 개별 행으로 펼치는데 이작업을 비정규화라고 함

#topic 3
126. 1-2
1) Azure AD 인증에는 MFA를 포함하는 옵션이 있음
2) Azure AD 인증은 포함된 데이터베이스 사용자를 사용하여 데이터베이스 수준에서 ID를 인증함

127. 2-5-1-6
1) 일반적인 데이터 관리 작업을 자동화하기 위해 계정 생성
2) Data Factort는 파이프라인 실행 데이터를 기본적으로 45일 동안만 저장하는데 Azure Monitor 진단 설정을 통해 보존 시간을 일 단위로 지정할 수 있음
3) 진단 설정을 추가
4) 진단 설정 및 작업 공간을 구성하기 위해 Log Analytics 사용

128. B
• TDE(투명한 데이터 암호화)는 저장 데이터를 암호화 및 해독하여 악의적인 활동의 위협으로부터 보호하고 데이터이스를 암호화하면 애플리케이션을 변경할 필요 없이 백업 및 트랜잭션 로그 발이이 암호화됨.

129. 4-1-5

130. 1-2 > 2-1
1) TDE는 고객 관리 키로 구성할 수 있음
2) 모음의 콘텐츠는 키와 비밀의 높은 내구성을 유지하기 위해 동일한 지역 내에서 최소 150마일 떨어진 지역 및 보조 지역으로 복제됨

131. B,D > A,C
• 분류 레이블은 대안으로 또는 권장 사항 기반 분류에 추가하여 수동으로 열을 분류할 수 있음
• Azure SQL 감사는 'data_sensitivity_information'이라는 감사 로그에 새 필드를 포함하도록 향상되었고 이 필드는 쿼리에서 반환된 데이터의 민감도 분류(레이블)를 기록함
☞ 로그는 쿼리를 실행한 사용자를 식별하는데 사용함

132. A > C
요구사항은 보기/유추 사항을 방지하는 것으로 열에 대한 액세스 불가가 더 알맞은 솔루션
> 데이터 마스킹은 데이터 유추로부터 보호하지 않음

133. A,C,E
• AAD에서 보안그룹을 생성 > Data Lake Storage Gen1 계정에 할당 > 보안그룹을 Data Lake Storage Gen1 파일 시스템에 ACL로 할당

134. C
• 연결된 서비스는 Data Factory가 외부 리소스에 연결하는데 필요한 연결 정보를 정의하는 연결 문자열과 매우 유사함

135. A > D
• 데이터 검색 및 분류는 Azure SQL Database, Azure SQL Managed Instance, Azure Synapse Analytics에 내장되어 있어 민감한 데이터를 검색,분류,레이블 지정 및 보고하기 위한 긴본 기능을 제공함
• 민감도 분류는 데이터 개인 정보보호 및 규정 준수 요구 사항 충족 지원

136. 1-1
1) Azure에서 관리 ID를 사용하면 개발자가 리소스에 대한 ID를 제공ㅎ고 이를 사용하여 자격증명을 관리할 필요가 없음
2) Data Factory는 특정 데이터를 나타내는 Azure 리소스에 대한 관리 ID와 연결할 수 있음

137. n-n-n
1) 분석가는 지역내 민감한 데이터에 액세스할 수 잇음
2~3) 엔지니어는 모든 숫자에 민감한 데이터에 액세스할 수 있고, Height는 CM에서 환자의 키

138. 2-5-4-3-1 (#3-13)
1) 관리 ID 할당(전제 조건으로 기존 관리 인스턴스가 필요함)
2) Key Vault 생성 및 설정에 대한 권하ㅇㄴ을 부여
3) Key Vault에 Key1 추가 권장되는 방법은 .pfx 파일에서 기존 키를 가져오거나 Key Vault에서 기존 키를 가져오는 것임
4) Server1에 대한 TDE 보호기로 Key 구성
5) Pool1에서 TDE 활성화

139. B
• Azure SQL DB는 현재 MS 관리 서비스 쪽 및 클라이언트 쪽 암호화 시나리오에 대해 저장 데이터 암호화를 지원함
• 현재 투명 데이터 암호화라는 SQL 기능을 통해 서버 암호화를 지원함
• Azure SQL DB 데이터의 클라이언트 쪽 암호화는 Always Encrypted 기능을 통해 지원됨

140. D > A
• Event Hub 생성 시 파티션 수를 지정할 수 있고 일부 시나리오에서는 Event Hub를 만든 후에 파티션을 추가해야 할 수 있음
☞ 파티션의 동적 추가는 Event Hubs의 프리미엄 및 전용 계층에서만 사용할 수 있음

141. B
• 복제된 테이블에는 모든 Compute 노드에서 사용 가능한 테이블의 전체 복사본이 있고 복제된 테이블의 조인에는 데이터 이동이 필요하지 않으므로 쿼리는 복제된 테이블에서 빠르게 실행됨

142. 4-2-3 > 3-3-3
질문은 비용을 최소화하도록 요구하므로 Parquet으로 이동

143. A,C
• 행 수준 보안을 사용하면 그룹 구성원 또는 실행 컨텍스트를 사용하여 데이터베이스 테이블의 행에 대한 액세스를 제한할 수 있음
• CREATE SECURITY POLICY 	Transact-SQL문과 인라인 테이블 반환함수로 생성된 조건자를 사용하여 RLS를 구현

144. A and B
• 이메일 주소 형식의 상수 문자열 접두사를 사용하여 첫 번째 문자를 노출하고 도메인을 XXX.com으로 바꾸는 이메일 마스킹 방법을 사용
☞ A,B 둘다 가능함

145. D
146~147. 문제없음

148. A
• 스토리지 계정이 Vnet에 연결된 경우 관리 ID 인증이 필요함

149. B
• SAS(공유 액세스 서명)는 저장소 계정의 리소스에 대한 보안 위임 액세스를 제공하고 SAS를 사용하면 클라이언트가 데이터에 액세스하는 방법을 세부적으로 제어할 수 있음

150. 1-2 > 3-3
1) Databricks에 액세스하려면 개인 토큰을 사용해야함
2) ADLS에 액세스하려면 공유 액세스 서명을 사용해야함

151. E
• 동적 데이터 마스킹은 고객이 애플리케이션 계층에 미치는 영향을 최소화하면서 공개할 민감한 데이터의 양을 지정할 수 있도록 하여 민감한 데이터에 대한 무단 액세스를 방지하는데 도움
• 데이터베이스의 데이터는 변경되지 않는 동안 지정된 데이터베이스 필드에 대한 쿼리 결과 세트의 민감한 데이터를 숨기는 정책 기반 보안 기능

152. D
• 연결된 서비스는 Data Factory가 외부 리소스에 연결하는 데 필요한 연결 정보를 정의하는 연결 문자열과 매우 유사함

#topic 4
153. C
• Stream Analytics 작업은 Event Hubs에서 이벤트를 수집하고 스트림에 대해 실시간 분석 쿼리를 실행함

154. 3-4 > 2-5
출력에 대한 파티션이므로 8개??
• Event Hubs의 경우 파티션 키를 명시적으로 설정해야함
☞ 병렬작업은 Azure Stream Analytics에서 가장 확장 가능한 시나리오, 쿼리의 한 인스턴스에 대한 입력의 한 파티션을 출력의 한 파티션에 연결함

155. 1-2-1-3 ??
• 일반적으로 팩트 테이블은 해시 분산되어 두 테이블 모두 해시 배포를 사용해야함
1) 해시분산을 사용, ProductKey는 조인에서 광범위하게 사용
2) 해시분산을 사용, 

156. A > B
• T-SQL 쿼리에 "WHERE" 절을 추가하면 쿼리 최적화 프로그램이 쿼리의 필터 기준을 충족하기 위해 관련 파티션에만 액세스할 수 있기 때문

157. B
•  해시 분산 테이블은 대규모 팩트 테이블에서 쿼리 성능을 향상 시키고 Columnstore 인덱스는 기존의 rowstore 인덱스보다 분석 및 데이터 웨어하우징 워크로드에서 최대 100배 더 나은 성능과 최대 10배 더 나은 데이터 압축을 달성할 수 있음
C,D : 라운드 로빈 테이블은 로딩 속도를 향상시키는데 유용

158. A?? C??

159. B
• 클러스터 이벤트 로그는 생성, 종료, 구성 편집 등과 같은 클러스터 수명 주기 이벤트를 캡처 디버깅에 사용할 수 있는 Apache Spark 드라이버 및 작업자 로그, 클러스터 초기화 스크립트 로그, 초기화 스크립트 디버깅에 유용함

160. D
• Data Factory는 파이프라인 실행 데이터를 45일동안만 저장하기 때문에 해당 데이터를 더 오래 보관하려면 Azure Monitor를 사용

161. C
• 백로그된 이벤트의 수의 메트릭에 대해 0이 아닌 값은 작업이 수신 이벤트를 따라갈 수 없음을 의미함
☞ 이 값이 천천히 증가하거나 지속적으로 0이 아닌 경우 작업을 확장해야함 > 스트리밍 단위를 조정

162. A
• Azure Databricks는 지난 30일 동안 종료된 최대 70개의 다목적 클러스터와 최근에 작업 스케줄러에 의해 종료된 최대 30개의 작업 클러스터에 대한 클러스터 구성 정보를 유지함
• 30일 이상 종료된 후에도 다목적 클러스터 구성을 유지하기 위해 관리자는 클러스터를 클러스터 목록에 고정할 수 있음

163. C
• 쿼리의 성능 용량은 사용자의 리소스 클래스에 따라 결정, 리소스 클래스는 쿼리 실행을 위한 컴퓨팅 리소스 및 동시성을 제어하는 Synapse SQL풀의 미리 결정된 리소스 제한임
• 리소스 클래스는 동시에 실행되는 쿼리 수와 각 쿼리에 할당된 컴퓨팅 리소스에 대한 제한을 설정하여 쿼리소스를 구성하는데 도움이 될 수 있음

164. D (4-12) > 4-28번과 같은 문제

• MS는 'sys.dm_pdw_nodes_db_partition_stats'를 사용하여 데이터의 왜곡을 분석할 것을 권장함

165. 1-2
• Azure Databricks에서 Log Analytics 작업 영역으로 애플리케이션 로그 및 메트릭을 보낼 수 있음


166. B
• DMW(동적 관리 보기)를 사용하여 SQL 풀에서 쿼리 실행 조사를 포함하여 워크로드를 모니터링할 수 있고 쿼리가 실패하거나 진행하는 데 시간이 오래 걸리는 경우 롤백되는 트랜잭션이 있는지 확인하고 모니터링할 수 있음

167. B (145번과 비슷한 시나리오)
• 백로그된 이벤트의 수의 메트릭에 대해 0이 아닌 값은 작업이 수신 이벤트를 따라갈 수 없음을 의미함
☞ 이 값이 천천히 증가하거나 지속적으로 0이 아닌 경우 작업을 확장해야함 > 스트리밍 단위를 조정

168. D ??
• 분석가는창고에 대한 거래를 일반적으로 분석하고 이것은 WarehouseID가 항상 where 절에 있음을 의미함 > 쿼리 성능을 향상시키려면 where절에 파티션이 있어야함
169. C,D
C,D는 스타 스키마를 설계하기 때문에 차원 테이블이 필요로함??

170. C (137번과 같은 문제)
• Stream Analytics 작업은 Event Hubs에서 이벤트를 수집하고 스트림에 대해 실시간 분석 쿼리를 실행함

171. B,D
• 캐시 적중은 로컬 SSD 캐시의 모든 columnstore 세그먼트 적중 합계이고 캐시 미스는 로컬 SSD 캐시에서 합산된 columnstore 세그먼트 누락
• 캐시 용량은 모든 노드의 로컬 SSD 캐시 저장 용량의 합계

172. 문제없음
173. A
컴퓨팅은 클러스터와 관련이 있음

174. D
• 마지막 동기화 시간 속성은 주 지역의 데이터가 보조 지역에 마지막으로 성공적으로 기록된 시간을 나타내고 마지막 동기화 시간 이전에 기본 지역에 작성된 모든 쓰기는 보조 위치에서 읽을 수 있음
• 마지막 동기화 시간 속성 이후 기본 지역에 대한 쓰기는 아직 읽기에 사용 가능하거나 사용 불가능할 수 있음

175. B
• 해당 오류가 발생하는 이유는 각 파일의 스키마가 다르기 때문
☞ PolyBase 외부 테이블 DDL은 가리킬 때 해당 디렉터리의 모든 파일을 재귀적으로 읽고 열 또는 데이터 형식 불일치가 발생하면 SSMS에서 해당 오류가 표시될 수 있음

176. D
• 데이터 왜곡(기울어진 테이블)은 데이터가 분포 전체에 고르게 분포되지 않음을 의미함

177. B
• 테이블에서 해시 분포는 팩트 테이블에서 쿼리 성능을 향상시킴

178. 3-3
1) 성공
2) web1에 성공 및 실패 경로가 모두 있기 때문에 실패
☞ 성공한 것으로 간주되려면 실패한 경로만 있어야함

179. D,E
1) Data Wangling은 Synapse Analytics가 아닌 ADF에서만 지원 가능함
2) Jar 활동에는 Databricks가 필요로함

180. D (148번과 같은 문제)

#topic 5
l
181. 좋은 문제가 아님 #사례1

182. 2-4 > 1-1 #사례1
1) "판매 거래 레코드가 포함된 파티션 데이터, 파티션은 월별로 효율적인 로드를 제공하도록 설계되어야 하고 경계값은 오른쪽 파티션에 속해야함"
2) "데이터 스토리지 비용과 성능을 예측할 수 있어야함"
☞ 전용 SQL 풀 크기는 DWU(데이터 웨어하우징 단위)에 의해 결정됨
☞ 전용 SQL 풀은 컬럼 스토리지가 있는 간계형 테이블에 데이터를 저장하며 이 형식은 데이터 저장 비용을 크게 줄이고 쿼리 성능을 향상시킴

183. D > A #사례1
"소매점 주소의 변경을 고려하여 대리키를 구현함"
• IDENTITY 속성을 사용하여 로드 성능에 영향을 주지않고 간단하고 효과적으로 데이터웨어하우스 모델을 설계할 때 테이블에 대리키를 만들 수 있음

184. 2-1 #사례1
1) "테이블은 약 2MB로, 소매점 판매 문의는 소매점 주소가 포함됨"
☞ 소매점 주소를 가져오는 쿼리만 있으면 되므로 복제 테이블 사용
2) "테이블은 약 5GB로 제품 ID를  기반으로 판매 거래 기록을 조인하고 필터링하는 쿼리가 최대한 빨리 완료되도록 해야함"
☞ 해시 분산 테이블은 대규모 팩트 테이블에서 쿼리 성능을 향상시킴

185. 2-4 #사례1
"파티션은 월별로 효율적인 로드를 제공하도록 설계되어야하고, 경계 값은 오른쪽 파티션에 속해야함

186. D #사례1
"2년이 지난 Twitter 피드 데이터 레코드를 제거함
• 데이터 세트에는 고유한 수명주기가 있음
• Azure Storage 수명 주기 관리는 Blob 데이터를 적절한 액세스 계층으로 전환하거나 데이터 수명 주기가 끝날 때 데이터를 만료하는 데 사용할 수 있는 규칙 기반 정책을 제공함

#topic 6
187. 2-3-1 > 1-2-1 #사례2
"이름,연락처 정보 및 로열티 번호를 포함한 고객 데이터는 Salesforce에서 가져오며 8시간마다 한 번씩 Azure로 가져올 수 있고 행 수정 날짜는 원본 테이블에서 신뢰할 수 없음"
"Azure 서비스의 수를 최소화"
2) 텀블링을 사용할 수 있지만 서비스의 수를 최소화해야하므로 8시간마다 예약창을 사용하는 것이 적절함
☞ 텀블링 창은 훨씬 더 많은 유연성을 갖춘 더 높은 전원/용량 창임
3) 8시간만다 한 번씩 Azure로 가져오는 복사 활동

#topic 7
188. B > C *** #사례2
"Litware는 온프레미스 네트워크와 Azure 사이에 Azure Express Route 또는 VPN을 구현할 계획이 없음"
• 가상 네트워크 규칙은 Azure SQL DB의 단일 데이터베이스 및 탄력적 풀에 대한 데이터베이스 서버 또는 SQL Data Warehouse의 데이터베이스에 대한 데이터베이스 서버가 가상 네트워크의 특정 서브넷에서 보낸 통신을 수락하는지 여부를 제어하는 방화벽 보안 기능
• 각 가상 네트워크 규칙은 서버의 특정 데이터베이스 하나가 아니라 전체 Azure SQL Database 서버에 적용됨(즉, 가상 네트워크 규칙은 데이터베이스 수준이 아니라 서버 수준에서 적용됨)

189. C (175번과 같은 문제)#사례2
"이러한 유형의 데이터는 분석적으로 관련이 없으므로 전화번호 등의 고객 연락처 정보에 대한 비즈니스 분석가의 접근을 제한함"

#topic 8
190. D (176번과 같은 문제)#사례2
"손상 또는 실수로 삭제된 경우 1시간 이내에 분석 데이터 저장소의 복사본을 신속하게 복원"
• Azure Stream Analytics 페어링된 지역 모델을 사용하여 작업 안정성 보장

191. C (173번과 같은 문제) #사례2
"이러한 유형의 데이터는 분석적으로 관련이 없으므로 전화번호 등의 고객 연락처 정보에 대한 비즈니스 분석가의 접근을 제한함"
• CLS를 사용하여 사용자 액세스를 관리할 수 있고 데이터 웨어하우스를 재설계할 필요 없이 보다 간단한 방식으로 테이블의 특정 열을 생성할 수 있음
• CLS를 사용하면 다른 응용 프로그램의 데이터에서 액세스 제한 논리를 유지 관리하거나 사용자 하위 집합에 대한 민감한 열을 필터링하기 위한 보기를 도입할 필요가 없음
#topic 9
192. D (190번과 같은 문제)
193. C
• 민감도 레이블은 데이터를 보호하지 않음
