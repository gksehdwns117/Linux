Case Study 1 - Contoso, Ltd
[Overview]
Contoso, Ltd. is a clothing retailer based in Seattle. The company has 2,000 retail stores across the United States and an emerging online presence.
(Contoso, Ltd.는 시애틀에 본사를 둔 의류 소매업체입니다. 이 회사는 미국 전역에 2,000개의 소매점을 가지고 있으며, 새롭게 온라인에 진출하고 있습니다.)
The network contains an Active Directory forest named contoso.com. The forest it integrated with an Azure Active Directory (Azure AD) tenant named contoso.com. Contoso has an Azure subscription associated to the contoso.com Azure AD tenant.
(네트워크에는 contoso.com이라는 이름의 Active Directory 포리스트가 포함되어 있습니다. contoso.com이라는 이름의 Azure Active Directory(Azure AD) 테넌트와 통합된 포레스트. Contoso는 'contoso.com' Azure AD 테넌트에 Azure 구독과 관련되어 있습니다.) 

[Existing Environment] - 기존환경
• Transactional Data
Contoso has three years of customer, transactional, operational, sourcing, and supplier data comprised of 10 billion records stored across multiple on-premises Microsoft SQL Server servers.
(Contoso는 여러 사내 Microsoft SQL Server에 저장된 100억 개의 레코드로 구성된 3년간의 고객, 트랜잭션, 운영, 소싱 및 공급업체 데이터를 보유하고 있습니다.)
The SQL Server instances contain data from various operational systems. The data is loaded into the instances by using SQL Server Integration Services (SSIS) packages.
(SQL Server 인스턴스에는 다양한 운영 체제의 데이터가 포함되어 있습니다. 데이터는 SQL Server Integration Services(SSIS) 패키지를 사용하여 인스턴스에 로드됩니다.)
You estimate that combining all product sales transactions into a company-wide sales transactions dataset will result in a single table that contains 5 billion rows, with one row per transaction.
(모든 제품 판매 트랜잭션을 전사적인 판매 트랜잭션 데이터 세트로 결합하면 트랜잭션당 한 줄씩 50억 개의 행이 포함된 단일 테이블이 생성될 것으로 예상합니다.)
Most queries targeting the sales transactions data will be used to identify which products were sold in retail stores and which products were sold online during different time periods. Sales transaction data that is older than three years will be removed monthly.
(판매 거래 데이터를 대상으로 한 대부분의 쿼리는 소매점에서 판매된 제품과 다른 기간에 온라인에서 판매된 제품을 식별하는 데 사용됩니다. 3년 이상 된 매매거래 데이터는 매월 삭제됩니다.)
You plan to create a retail store table that will contain the address of each retail store. The table will be approximately 2 MB. Queries for retail store sales will include the retail store addresses.
(각 소매점의 주소가 들어 있는 소매점 테이블을 만들 계획입니다. 테이블은 약 2MB입니다.소매점 판매 문의에는 소매점 주소가 포함됩니다.)
You plan to create a promotional table that will contain a promotion ID. The promotion ID will be associated to a specific product. The product will be identified by a product ID. The table will be approximately 5 GB.
(프로모션 ID가 포함된 프로모션 테이블을 만들 계획입니다. 프로모션 ID는 특정 제품에 연결됩니다. 제품은 제품 ID로 식별됩니다. 테이블은 약 5GB입니다.)
• Streaming Twitter Data
The ecommerce department at Contoso develops an Azure logic app that captures trending Twitter feeds referencing the company's products and pushes the products to Azure Event Hubs.
(Contoso의 전자상거래 부문은 Azure 로직 앱을 개발하여 회사의 제품을 참조하는 트렌드 트위터 피드를 캡처하고 Azure Event Hubs에 제품을 푸시합니다.)

[Planned Changes and Requirements]
• Planned Changes
Contoso plans to implement the following changes:
- Load the sales transaction dataset to Azure Synapse Analytics.
(판매 트랜잭션 데이터 세트를 Azure Synapse Analytics에 로드합니다.)
- Integrate on-premises data stores with Azure Synapse Analytics by using SSIS packages
(SSIS 패키지를 사용하여 사내 데이터스토어를 Azure Synapse Analytics와 통합합니다.).
- Use Azure Synapse Analytics to analyze Twitter feeds to assess customer sentiments about 
products.
(Azure Synapse Analytics를 사용하여 Twitter 피드를 분석하여 제품에 대한 고객의 감정을 평가합니다.)
• Sales Transaction Dataset Requirements
Contoso identifies the following requirements for the sales transaction dataset:
- Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right.
(판매 거래 레코드를 포함하는 데이터 파티션화. 파티션은 월별로 효율적인 부하를 제공하도록 설계해야 합니다. 경계 값은 오른쪽 파티션에 속해야 합니다.)
- Ensure that queries joining and filtering sales transaction records based on product ID complete as quickly as possible.
(제품 ID를 기반으로 영업 거래 기록에 가입하고 필터링하는 조회가 가능한 한 빨리 완료되도록 하십시오.)
- Implement a surrogate key to account for changes to the retail store addresses.
(소매점 주소의 변경을 고려하여 대리 키를 구현합니다.)
- Ensure that data storage costs and performance are predictable.
(데이터 스토리지 비용과 성능을 예측할 수 있는지 확인합니다.)
- Minimize how long it takes to remove old records.
(오래된 레코드를 삭제하는 데 걸리는 시간을 최소화합니다.)
• Customer Sentiment Analytics Requirements
Contoso identifies the following requirements for customer sentiment analytics:
- Allow Contoso users to use PolyBase in an Azure Synapse Analytics dedicated SQL pool to query the content of the data records that host the Twitter feeds. Data must be protected by using row-level security (RLS). The users must be authenticated by using their own Azure AD credentials.
(Contoso 사용자가 Azure Synapse Analytics 전용 SQL 풀의 PolyBase를 사용하여 Twitter 피드를 호스트하는 데이터 레코드의 내용을 조회할 수 있도록 합니다. 데이터는 RLS(Row-Level Security)를 사용하여 보호해야 합니다. 유저는, 독자적인 Azure AD credential을 사용해 인증할 필요가 있습니다.)
- Maximize the throughput of ingesting Twitter feeds from Event Hubs to Azure Storage without purchasing additional throughput or capacity units.
(처리량이나 용량 유닛을 추가 구입하지 않고 이벤트 허브에서 Azure 스토리지로 Twitter 피드를 수집하는 스루풋을 최대화합니다.)
- Store Twitter feeds in Azure Storage by using Event Hubs Capture. The feeds will be converted into Parquet files.
(이벤트 허브 캡처를 사용하여 Azure 스토리지에 트위터 피드를 저장합니다. 피드가 Parquet 파일
로 변환됩니다.)
- Ensure that the data store supports Azure AD-based access control down to the object level.
(데이터 저장소에서 Azure AD 기반 액세스 제어를 개체 수준까지 지원하는지 확인하십시오.)
- Minimize administrative effort to maintain the Twitter feed data records.
(Twitter 피드 데이터 레코드를 유지하기 위한 관리 작업을 최소화합니다.)
- Purge Twitter feed data records that are older than two years.
(2년 이상 된 트위터 피드 데이터 레코드를 삭제합니다.)
• Data Integration Requirements
Contoso identifies the following requirements for data integration:
- Use an Azure service that leverages the existing SSIS packages to ingest on-premises data into datasets stored in a dedicated SQL pool of Azure Synapse Analytics and transform the data.
(기존 SSIS 패키지를 활용하는 Azure 서비스를 사용하여 Azure Synapse Analytics의 전용 SQL 풀에 저장된 데이터셋으로 사내 데이터를 수집하고 데이터를 변환합니다.)
- Identify a process to ensure that changes to the ingestion and transformation activities can be version-controlled and developed independently by multiple data engineers
(수집 및 변환 활동에 대한 변경을 여러 데이터 엔지니어가 독립적으로 제어 및 개발할 수 있도
록 하는 프로세스를 특정한다.)
 
Case Study 2 - Litware, Inc
[Overview]
Litware, Inc. owns and operates 300 convenience stores across the US. The company sells a variety of packaged foods and drinks, as well as a variety of prepared foods, such as sandwiches and pizzas.
Litware, Inc.는 미국 전역에 300개의 편의점을 소유하고 운영하고 있습니다. 이 회사는 샌드위치와 피자 같은 다양한 조리 식품뿐만 아니라 다양한 포장 식품과 음료도 판매한다.

Litware has a loyalty club whereby members can get daily discounts on specific items by providing their membership number at checkout.
Litware, Inc.는 회원가입 시 회원번호를 알려줌으로써 특정 아이템을 매일 할인받을 수 있는 로열티 클럽을 운영하고 있다.
Litware employs business analysts who prefer to analyze data by using Microsoft Power BI, and data scientists who prefer analyzing data in Azure Databricks notebooks.
Litware는 Microsoft Power BI를 사용하여 데이터를 분석하는 비즈니스 분석가 및 Azure 
Databricks 노트북의 데이터 분석을 선호하는 데이터 과학자를 고용하고 있습니다.

[Requirements. Business Goals]
Litware wants to create a new analytics environment in Azure to meet the following requirements :
- See inventory levels across the stores. Data must be updated as close to real time as possible.
스토어 전체의 인벤토리 레벨을 참조해 주세요. 데이터는 가능한 한 실시간으로 업데이트해야함.
- Execute ad hoc analytical queries on historical data to identify whether the loyalty club discounts increase sales of the discounted products.
이력 데이터에 대한 임시 분석 쿼리를 실행하여 로열티 클럽 할인이 할인된 제품의 매출을 증가시키는지 확인함
- Every four hours, notify store employees about how many prepared food items to produce based on historical demand from the sales data. 
매 4시간마다 판매 데이터의 과거 수요에 따라 제조할 식품 품목의 수를 매장 직원에게 통지함

[Requirements. Technical Requirements]
Litware identifies the following technical requirements:
- Minimize the number of different Azure services needed to achieve the business goals
비즈니스 목표를 달성하기 위해 필요한 다양한 Azure 서비스 수를 최소화합니다.
- Use platform as a service (PaaS) offerings whenever possible and avoid having to provision virtual machines that must be managed by Litware.
가능한 한 Platform as a Service(PaaS) 서비스를 사용하여 Litware에서 관리해야 하는 가상 머신을 프로비저닝할 필요가 없습니다.
- Ensure that the analytical data store is accessible only to the company’s on-premises network and Azure services.
분석 데이터 스토어는 회사의 사내 네트워크 및 Azure 서비스에서만 액세스할 수 있도록 합니다.
- Use Azure Active Directory (Azure AD) authentication whenever possible.
가능한 한 Azure Active Directory(Azure AD) 인증을 사용합니다.
- Use the principle of least privilege when designing security.
보안을 설계할 때는 최소 특권의 원칙을 사용합니다.
- Stage inventory data in Azure Data Lake Storage Gen2 before loading the data into the analytical data store. Litware wants to remove transient data from Data Lake Storage once the data is no longer in use. Files that have a modified date that is older than 14 days must be removed.
데이터를 분석 데이터스토어에 로드하기 전에 Azure Data Lake Storage Gen2에서 인벤토리 데이터를 준비합니다. Litware는 데이터가 더 이상 사용되지 않게 되면 Data Lake Storage에서 임시 데이터를 제거하려고 합니다. 수정된 날짜가 14일보다 오래된 파일은 제거해야 합니다.
- Limit the business analysts’ access to customer contact information, such as phone numbers, because this type of data is not analytically relevant.
이러한 유형의 데이터는 분석적으로 관련이 없으므로 전화번호 등의 고객 연락처 정보에 대한 비즈니스 분석가의 접근을 제한합니다.
- Ensure that you can quickly restore a copy of the analytical data store within one hour in the event of corruption or accidental deletion.
손상 또는 실수로 삭제된 경우 1시간 이내에 분석 데이터 저장소의 복사본을 신속하게 복원할 수 있습니다.

[Requirements. Planned Environment]
Litware plans to implement the following environment:
- The application development team will create an Azure event hub to receive real-time sales data, including store number, date, time, product ID, customer loyalty number, price, and discount amount, from the point of sale (POS) system and output the data to data storage in Azure.
애플리케이션 개발팀은 Azure 이벤트 허브를 만들어 POS(Point of Sale) 시스템에서 매장 번호, 날짜, 시간, 제품 ID, 고객 충성도 번호, 가격, 할인 금액 등 실시간 판매 데이터를 받아 Azure의 데이터 스토리지에 출력합니다.
- Customer data, including name, contact information, and loyalty number, comes from Salesforce and can be imported into Azure once every eight hours. Row modified dates are not trusted in the source table.
이름, 연락처 정보, 로열티 번호 등의 고객 데이터는 Salesforce에서 가져오며 8시간마다 한 번씩 Azure로 가져올 수 있습니다. 행 수정 날짜는 원본 테이블에서 신뢰할 수 없습니다.
- Product data, including product ID, name, and category, comes from Salesforce and can be imported into Azure once every eight hours. Row modified dates are not trusted in the source table.
제품 ID, 이름 및 카테고리를 포함한 제품 데이터는 Salesforce에서 가져오며 8시간마다 한 번씩 
Azure로 가져올 수 있습니다. 행 수정 날짜는 원본 테이블에서 신뢰할 수 없습니다.
- Daily inventory data comes from a Microsoft SQL server located on a private network.
일별 인벤토리 데이터는 개인 네트워크에 있는 Microsoft SQL Server에서 가져옵니다.
- Litware currently has 5 TB of historical sales data and 100 GB of customer data. The company expects approximately 100 GB of new data per month for the next year.
Litware는 현재 5TB의 과거 판매 데이터와 100GB의 고객 데이터를 보유하고 있습니다. 동사는, 향후 1년간, 매월 약 100 GB의 새로운 데이터를 예상하고 있습니다.
- Litware will build a custom application named FoodPrep to provide store employees with the calculation results of how many prepared food items to produce every four hours.
리트웨어는 매장 직원들에게 4시간마다 몇 개의 준비된 식품을 생산해야 하는지에 대한 계산 결과를 제공하기 위해 FoodPrep이라는 이름의 맞춤형 애플리케이션을 구축할 것이다.
- Litware does not plan to implement Azure ExpressRoute or a VPN between the on-premises network and Azure
Litware는 온프레미스 네트워크와 Azure 사이에 Azure Express Route 또는 VPN을 구현할 계획이 없습니다.
