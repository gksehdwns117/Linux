#Topic1

1. D > C
매니저를 식별하기 위해 추가 열이 필요로함, 데이터 유형을 EmployeeKey, Int열로 사용함

2. A > B
• Where절에서 EmployeeName이 아닌 name열을 사용함
☞ 테이블에 존재하지 않는 열이므로 오류발생

3. 4-6-5 > 4-1-3
• 파티션이 빈 파티션으로 전환(Switch)되면 원래 테이블에서 파티션을 Drop
• SQL Data Warehouse는 파티션 분할, 병합 및 전환을 지원
> 두 테이블 간에 파티션을 전환하려면 파티션이 해당 경계에 맞춰 정렬되고 테이블 정의가 일치하는지 확인해야함
1) SalesFact와 동일한 스키마를 가진 SalesFact_Work라는 빈 테이블을 생성
2) 오래된 데이터가 포함된 파티션을 SalesFact_Work로 전환
3) SalesFact_Work 테이블 삭제

4. B
• 사용된 쿼리는 폴더의 모든 파일만 읽으며, 폴더의 파일을 재귀적으로 쿼리하려면 쿼리에서 /**(와일드카드)를 지정해야함.
• 외부 테이블에 대한 재귀 데이터 Hadoop 외부 테이블과 달리 기본 외부 테이블은 경로 끝에 /**(와일드카드)를 지정하지 않는 한 하위 폴더를 반환하지 않음

5. 3-1
1) Parquet - 열 지향 바이너리 파일 형식으로 몇 개의 열만 읽는 데 가장 적합한 솔루션
2) Avro - 행 기반 형식이며 논리적인 유형 타임스탬프가 있음, Avro 형식은 여러 이벤트/메시지를 연속적으로 작성하는 Event Hub 또는 Kafka와 같은 메시지 버스에서 잘 작동함
• TSV는 Azure Data Lake Storage Gen2에 대한 옵션이 아님


6. C > D
• Directory 구조의 끝에 날짜를 넣는 중요한 이유는 특정 지역이나 주제를 사용자/그룹에 잠그고 싶다면 POSIX 권한으로 쉽게 할 수 있는데 그렇지 않고 특정 보안 그룹이 영국 데이터 또는 특정 비행기만 볼 수 있도록 제한해야 하는 경우 날짜 구조가 앞에 있는 경우 매시간 Directory 아래의 수많은 Directory에 대해 별도의 권한이 필요함
• 날짜 구조가 앞에 있으면 시간이 지남에 따라 Directory 수가 기하급수적으로 증가함

7. 3-1 (5번 문제와 비슷한 시나리오)
1) Parquet은 데이터를 열에 저장하는 반면 Avro는 데이터를 행 기반 형식으로 저장하여 본질적으로 열 기반 데이터 저장소는 읽기가 많은 분석 워크로드에 최적화되어 있는 반면 행 기반 데이터베이스는 쓰기가 많은 트랜잭션 워크로드에 가장 적합함
2) Avro 스키마는 JSON 형식을 사용하여 생성되고 타임스탬프를 지원함

8. 1-3 > 3-3
1) Preserver hierarchy ADF는 처리에만 사용되며 Synapse는 싱크로 시냅스는 병렬 처리 능력을 가지고 있기 때문에 다른 폴더에 있는 파일을 처리할 수 있어 성능이 향상됨
2) Parquet은 스키마 속성을 지원함

9. 3-3-3-1 ***
1~3) 팩트 테이블이 연결된 차원 테이블과 호환되지 않는 열에 배포되는 경우가 많기 대문에 복제된 테이블은 작은 별 스키마 차원 테이블에 이상적임.
4) 팩트 테이블의 경우 클러스터형 columnstore 인덱스와 함께 해시 분포를 사용하여 동일한 배포 열에서 두개의 해시 테이블을 조인하면 성능이 향상됨.

10. 3-2

11. 3-5 > 3-4
1) 테이블 배포 옵션에는 'DISTRIBUTION=HASH(distribution_column_name)'가 포함되며, 
distribution_column_name에 저장된 값을 해싱하여 각 행을 하나의 배포에 할당함
2) PARTITION 할당

12. A
• SCD2는 차원 구성원의 버전관리를 지원
☞ 종종 소스 시스템은 버전을 저장하지 않으므로 데이터 웨어하우스 로드 프로세스는 차원 테이블의 변경사항을 감지하고 관리하는데 이 경우 차원 테이블은 구성원 버전에 대한 고유 참조를 제공하기 위해 대리 키를 사용해야함

13. A,B,F
F > A > B
• Synapse가 DataLake에 액세스할 수 있도록 구성해야하므로 관리 ID를 생성하고 이미 데이터 레이크에 액세스할 수 있으므로 이를 영업그룹에 추가해야함.

14. 1-2 > 4-2
• 기본 마스킹은 지정된 필드의 데이터 유형에 따른 전체를 마스킹하는 기능을 함
• 관리자 권한이 있는 사용자는 항상 마스킹에서 제외되며 마스크 없이 원본 데이터를 봄
1) 'YearlyIncome' 열은 money 데이터 유형으로 숫자 데이터 유형
(bigint,bit,decimal,int,money,numeric,smallint,float,real)은 0 값을 사용함
2) User1은 serveradmin으로 쿼리한 데이터의 값을 그대로 받아볼 수 있음

15. B > C
• 외부 테이블에는 DDL(데이터 정의어)문만 허용함
☞ CREATE TABLE 및 DROP TABLE
☞ CREATE STATISTICS 및 DROP STATISTICS
☞ CREATE VIEW 및 DROP VIEW

16. 2-3 > 1-3
1) 파일에 변형이 없기 때문에 소스 및 싱크로 바이너리가 될 수 있음
☞ 바이너리 데이터 세트를 사용할 대 서비스는 파일 콘텐츠를 구문 분석하지 않고 있는 그대로 처리
(파일을 구문 분석하지 않으면 시간이 절약됨)
2) PreserveHierachy 설정은 대상 폴더의 파일 계층을 유지, 소스 폴더에 대한 소스 파일의 상대 경로는 대상 폴더에 대한 대상 파일의 상대 경로와 동일함

17. B?? A?? **
GRS는 RA-GRS보다 저렴함
GRS는 자동 장애조치를 하지 않음?? > 해당 문제는 자동 장애조치에 대한 요구사항이 없음

18. D
• LRS는 단일 데이터센터에 3번의 복제작업
☞ 데이터 센터 자체가 실패하는 경우 다른 데이터 센터에서 복구 > ZRS

19. 3-3-3
1) 라운드 로빈은 가장 간단한 배포 모델이며 쿼리에는 적합하지 않지만 처리는 빠름
2) 힙 테이블은 준비 테이블과 같은 데이터를 로드하는 데 특히 유용할 수 있음
3) 날짜별 파티션은 삽입하는 데이터의 새 파티션을 숨기고 다음 새 파티션을 숨김 해제할 수 있기 때문에 스테이지 대상에 데이터가 있을 때 유용하지만 해당 문제는 "매일 로드하기 전에 테이블이 잘림"라고 명시되어 있으므로 실제 스테이징 테이블이며 액세스 권한이 있는 사용자 없음

20. B ***
• 해시 분산 테이블은 대규모 팩트 테이블에서 쿼리 성능을 향상시킴

21. 4-1-3 > 3-1-4 ??
3) 팩트 테이블은 관찰 또는 이벤트를 저장하며 판매 주문, 재고 잔고, 환율, 온도 등이 될 수 있음

22. A
• 모든 파일 형식은 성능과 특성이 다르기 때문에 빠른 로드를 위해 구분된 압축 텍스트 파일을 사용
23. B
24. B

25. B
• 구체화된 뷰를 사용하면 기본 테이블에서 데이터를 변경할 수 있고 데이터는 쿼리 조각에 적용될 수 있어 이 지원을 통해 더 빠른 성능을 위해 일부 계산을 공유하는 다른 쿼리에서 동일한 구체화된 뷰를 사용할 수 있음
• Azure Synapse의 전용 SQL 풀에 대한 구체화된 뷰는 쿼리 변경 없이 빠른 성능을 얻기 위해 복잡한 분석 쿼리에 대한 유지 관리가 적은 방법을 제공함

26. A,D (CSV와 Parquet 둘다 정답이 될 수 있음)
• synapse Analytics는 Parquet 또는 CSV를 기반으로 하고 Azure Storage에 있는 각 Spark 외부 테이블에 대해 서버리스 SQL 풀 데이터벵스에 외부 테이블이 생성됨


27. D 
• Azure Data Lake Store > JAVA,Kafka > Databricks

28. B > D
• 일괄처리의 한가지 예는 대규모의 플랫, 반구조화된 CSV/JSON 파일 세트를 추가 쿼리에 사용할 준비가 된 도식화되고 구조화된 형식으로 병합하는 것

29. 3-1
1) 30일 이후에 Cool로 이동
2) "container1/contosoo"로 시작하는 모든 항목과 일치하고 답변의 csv가 일치하는 유일한 항목

30. C > D
"분석가는 주어진 월에 대한 트랜잭션을 가장 일반적으로 분석함"
☞ 해당 문구로 보아 'TransactionMonth" 열은 Where 절에서 사용됨
• where 절 열에서 파티션을 나누면 처리할 데이터 양이 크게 줄어들어 성능이 향상됨

31. 1-2 > 3-2
1) 데이터는 최소 180일 동안 아카이브 계층에 남아 있어야하며 그렇지 않으면 조기 삭제 요금이 부과됨
2) Blob Storage 수명 주기 관리는 지정된 조건이 충족될 때 원하는 액세스 계층으로 데이터를 전환하는데 사용할 수 있는 규칙 기반 정책을 제공함

32. A > B
• Databricks와 PolyBase를 모두 지원하려면 Parquet이 필요로함
• Parquet은 빠르게 검색하고 자체적으로 메타데이터를 유지할 수 있음

33. B > C
stg.Sales라는 스테이징 테이블이 소스가 되고 dbo.sales라는 팩트 테이블이 타겟이 됨.
• 롤백을 제거하는 방법은 데이터 관리를 위해 파티션 전환과 같은 멭데이터 전용 작업을 사용하는 것임

34. A,B,E
• 유형 2 SCD 변경 사항을 지원하려면 테이블에 4개의 열을 추가해야함
☞ 대리키- 원래 ID가 더 이상 필ㅇ한 특정 레코드를 식별하기에 충분하지 않으므로 새 ID를 생성해야함
☞ 현재 플래그 - 각 레코드의 현재 버전만 반환하는 빠른 방법
☞ 시작날짜 - 특정 기록 버전이 활성화된 날짜
☞ 종료날짜 - 특정 기록 버전 레코드가 활성화된 날짜
C : 대리 키는 데이터베이스에서 하나의 고유한 행을 식별하고 비즈니스 키는 모델링된 세계의 하나의 고유한 엔터티를 식별함
35. 1-3 > 3-1
1) 비정규화는 상위 정규형 관계의 결합을 기본 관계로 저장하여 상위 정규형을 하위 정규형으로 변환하는 프로세스로 데이터베이스에 업데이트 이상을 가져오는 비용으로 데이터 검색의 성능을 향상시킴
2) 'New ID columns' 단계에서 관계 축소 전략을 사용하여 분류 엔터티를 구성 요소 엔터티로 축소하여 팩트 테이블에 직접 연결되는 단일 부품 키가 있는 평면 차원 데이블을 얻을 수 있음

36. 4-3-3 > 2-3-3?? 1-3-3?? ***

37. A
• 각 파티션에는 약 1백만개의 레코드가 있어야하함, 전용 SQL 풀에는 이미 60개의 파티션이 존재함
☞ 레코드/(파티션*60)=1,000,000
☞ 파티션=레코드/(1,000,000*60)
2,400,000,000/60,000,000=40

38. 3-1 > 2-1
surrogate(대리의)
1) Sellenddate 및 Sellstartdate는 버전 관리용이 아니라 제품의 속성이기 때문에 Tpye 1 SCD
2) 종종 소스 시스템은 버전을 저장하지 않으므로 데이터 웨어하우스 로드 프로세스는 차원 테이블의 변경 사항을 감지하고 관리하는데 이 경우 차원 테이블은 차원 구성원 버전에 대한 고유 참조를 제공하기 위해 대리키를 사용해야함

39. B
• 해시 분산 테이블은 대규모 팩트 테이블에서 쿼리 성능을 향상시킴
C : 라운드 로빈 테이블은 로딩 속도를 향상시키는데 유용함

40. A
Parquet : 파일보다 적은 열로 외부 테이블을 생성하는 것은 파일 자체에 영향을 미치지 않으며 실제로 실패하므로 저장 비용에 도움이 되지 않음

41. 5-1-2 > 2-1-5
외부 테이블 원본 생성 > 외부 파일 형식 개체 생성 > 외부 테이블 생성
• Synapse SQL에서는 전용 SQL 풀 또는 서버리스 SQL 풀을 사용하여 외부 테이블로 데이터를 읽고 쓸 수 있음 > 외부 테이블은 Hadoop,Azure Storage Blob,Azure Data Lake Storage에 있는 데이터를 가리키며 Azure Storage의 파일에서 데이터를 읽거나 쓰는 데 사용됨.

42. C,D > C,E
employee 정보는 차원 테이블로 거래 정보를 fact 테이블로
• 차원 테이블에는 변경될 수 있지만 일반적으로 드물게 변경되는 속성 데이터가 포함됨
• 팩트 테이블에는 트랜잭션 시스템에서 일반적으로 생성된 다음 전용 SQL 풀에 로드되는 양적 데이터가 포함됨
43. C
• Type 2 SCD는 차원 구성원의 버전 관리를 지원, 종종 소스 시스템은 버전을 저장하지 않으므로 데이터 웨어하우스 로드 프로세스는 차원 테이블의 변경 사항을 감지하고 관리함
☞ 이 경우 차원 테이블은 차원 구성원 버전에 대한 고유 참조를 제공하기 위해 대리키를 사용해야함
B : Type 1 SCD는 항상 최신 값을 반영하며 소스 데이터의 변경 사항이 감지되면 차원 테이블 데이터를 덮음
D : Type 3 SCD는 차원 구성원의 두 가지 버전을 별도의 열로 저장하는 것을 지원하고 테이블에는 구성원의 현재 값과 구성원의 원래 값 또는 이전 값에 대한 열이 포함됨

44. 4-2-3 > 2-4-3 ***
1) Azure Data Lake Store Gen1/2를 참조하기 위해 abfs 위치를 사용한느 외부 데이터 원본 만들기
2) 외부 파일 형식을 만들고 First_Row 옵션을 설정(외부 파일 형식 생성)
3) 거부 옵션을 구성하여 거부 값 또는 백분율을 지정함
• PolyBase를 사용하려면 외부 데이터를 참조할 외부 테이블을 생성해야함.

45. 1-3 > 3-1
1) 'RANGE RIGHT FOR VALUES'는 PARTITON과 함께 사용됨
2) [TransactionDateID]는 날짜열의 파티션임

46. D
47. 5-4-1
1~2)Select,explode
3) 

48. 3-2-2
49. A > C
• 서버리스 SQL 풀을 사용하면 데이터 레이크의 데이터를 쿼리할 수 있고 반정형 및 비정형 데이터 쿼리를 수용하는 TSQL 쿼리 노출 영역을 제공함

50. D
• 클러스터를 4배 더 빠르게 시작하고 확장할 수 있게 해주는 가상 머신 인스턴스의 관리형 캐시인 Databricks Polls 생성

51. 3-4 > 1-4
1) 두번째 사진에서 redata/2020—3-20 경로 확인 가능
52. n-y-y
1) 
2) 명시적으로 재분할된 데이터의 두 스트림을 결합할 때 이러한 스트림은 동일한 파티션 키와 파티션 수를 가져야함
3) SU(스트리밍 단위)는 Stream Analytics 작업을 실행하기 위해 할당된 컴퓨팅 리소스를 나타내느데 이 SU가 많을수록 작업에 대한 CPU 및 메모리 수가 많이 할당되고 일반적으로 쿼리에 대해 기본 6개의 SU로 시작하는 것이 좋음 > 해당 문제는 10개의 파티션이 있으므로 60의 SU가 좋음

53. 1-1 > 1-3
1) 외부 테이블은 파일에서 데이터를 읽거나 Azure Storage의 파일에 데이터를 쓰는 데 사용됨
2) OPENROWSET

54. 2-3 > 3-1

55. B
56. 2-5
57. 3-2

# Topic2
58. B > A
• 높은 동시성 클러스터(High Concurrency)는 Scala를 지원하지 않음
데이터 엔지니어 - 공유를 위해 제공되는 높은 동시성 클러스터 
작업 - Scala를 사용하므로 표준 클러스터
데이터 과학자 - 120분후에 자동으로 종료되고 Scala를 사용하므로 표준 클러스터
59. A > B
데이터 엔지니어 - 공유를 위해 제공되는 높은 동시성 클러스터 
작업 - Scala를 사용하므로 표준 클러스터
데이터 과학자 - 120분후에 자동으로 종료되고 Scala를 사용하므로 표준 클러스터

60. 2-1 > 1-2
1) Azure Stream Analytics를 사용하여 실시간 IoT 데이터 스트림을 처리할 수 있음
2) Geospatial(지리공간) 기능을 통해 Azure Stream Analytics를 사용하여 차량 관리, 승차 공유, 연결된 자동차 및 자산 추적과 같은 시나리오에 대한 애플리케이션을 빌드할 수 있음

61. C,D
• 파티셔닝(병렬화)을 사용하면 파티션 키를 기반으로 데이터를 하위 집합으로 나눌 수 있음
☞ 입력이 키로 분할된 경우 Stream Analytics 작업에 입력을 추가할 때 이 파티션 키를 지정하는 것이 좋음
☞ Stream Analytics 작업 크기 조정은 입력 및 출력의 파티션을 활용함
D : 스케일링(작업수 확장)은 최적화가 아님
62. D > C
• Data Factory는 기본적으로 Azure Event Grid와 통합되므로 이러한 이벤트에서 파이프라인을 트리거할 수 있음

63. B
• Azure Databricks에는 대화형 클러스터와 자동화 클러스터의 두가지 유형이 있음
☞ 대화형 클러스터를 사용하여 대화형 노트북과 공동으로 데이터를 분석
☞ 자동화된 클러스터를 사용하여 빠르고 강력한 자동화된 작업을 실행함

64. 1-2-4 > 2-4-2
1) 해당 단계는 10분 창에서 최대 타임스탬프, 즉 해당 창에 대한 마지막 이벤트의 타임스탬프를 탐색하는 쿼리
2) 텀블링 창은 일련의 고정 크기, 비중첩 및 연속 시간 간격
3) DATEDIFF는 두 DataTime 필드 간의 시간 차이를 비교하여 반환되는 날짜별 함수

65. D > A
• 활동은 종속성을 통해 함께 연결되며 종속성의 조건은 성공, 실패, 건너뛰기, 완료됨 중 하나

66. 1-1-2-2 > 2-1-2-2
1) Azure Data Factory 파이프라인은 SSIS(SQL Server Integration Services) 패키지를 실행할 수 있는 기능을 제공함
2) Data Lake Storage Gen1은 무제한 저장소를 제공함
3) Azure Databricks는 Azure AD 통합을 포함하여 엔터프라이즈급 Azure 보안을 제공함
☞ Azure Databricks를 사용하면 몇 분 만에 Apache Spark 환경을 설정하고 자동 크기 조정을 수행하고 대화형 작업 영역에서 공유 프로젝트에 대해 공동 작업을 수행할 수 있음
4) Azure Synapse Analytics/SQL Data Warehouse는 데이터를 컬럼 스토리지가 있는 관계형 테이블에 저장함

67. 1-2
1) Case는 조건 목록을 평가하고 가능한 여러 결과 표현식 중 하나를 반환함
☞ Case는 유효한 표현식을 허용하는 모든 명령문이나 절에서 사용할 수 있음

68. 1-3 > 4-2
1) CSV 파일의 내용을 확인하는 가장 쉬운 방법은 OPENROWEST 함수에 파일 URL을 제공하고 csv Format을 지정하는 것임
2) OPENROWEST 와 같이 매핑된 드라이브를 사용하여 Azure File Storage 공유에서 JSON 파일에 액세스 할 수 있음

69. 2-5 > 5-1
1) PIVOT은 식의 한 열에 있는 고유한 값을 출력의 여러 열로 변환하여 테이블 반환식을 회전하고 최종 출력에서 원하는 나머지 열 값에 필요한 집계를 실행함
☞ SQL Server에서 행을 열로 변환하기 위해서는 PIVOT()함수를 이용하면됨
2) SQL Server에서 정수 값을 DECIMAL 데이터 형식으로 변환하려면 CAST() 함수를 사용

70. A > D
• ADF 주석은 파이프라인, 데이터세트, 연결된 서비스 및 트리거와 같은 특정 Factory 리소스에 추가할 수 있는 정보 태그로 주석을 추가하여 리소스를 쉽게 필터링하고 검색할 수 있음

71. y-n-n > y-n-y
1) 'spark.databricks.cluster.profile' : "serverless"는 클러스터가 다중 사용자를 지원하는 높은 동시성 클러스터임을 의미함
2) 새 클러스터에서 작업을 실행할 때 작업은 작업 워크로드 가격에 따라 데이터 엔지니어링 워크로드로 처리되고 기존 클러스터에서 작업을 실행할 때 작업은 다목적 워크로드 가격이 적용되는 데이터 분석(범용) 워크로드로 처리됨
3) Databricks의 Delta Lake를 사용하면 워크로드 패턴을 기반으로 Delta Lake를 구성할 수 있음

72. A > B
• Databricks는 Azure Event Hubs의 거의 실시간 데이터를 지원하고 R,SQL,Python,Scala,Java에 대한 지원을 포함함
C : Stream Analytics가 JavaScript, C# 사용자 정의 함수(UDF)로 SQL 언어 확장을 지원하지만 Python에 대한 지원은 없음

73. 1-3 > 1-2
https://docs.microsoft.com/en-us/sql/t-sql/statements/create-partition-function-transact-sql?view=sql-server-ver15
1) Rang Right는 1월 1일부터 12월 31일까지의 달력 비교에 적합

74. B,E
• 유형 3 SCD는 차원 구성원의 두가지 버전을 별도의 열로 저장하는 것을 지원, 테이블에는 구성원의 현재 값과 구성원의 원래 값 또는 이전 값에 대한 열이 포함되어 추가 열을 사용하여 하나의 주요 기록 인스턴스를 추적함
☞ Origin 기존 버전과 Current 최신 버전을 비교하기 위함

75. A ***
• 일련의 고정 크기, 비중첩 및 연속 시간 간격인 텀블링 창을 사용하는 솔루션
76. B
• 일련의 고정 크기, 비중첩 및 연속 시간 간격인 텀블링 창을 사용하는 솔루션

77. 1-1 > 2-2
1) DATADIFF 함수는 지정된 시작 날짜와 종료 날짜 사이에 교차하는 지정된 날짜 부분 경계의 개수(부호 있는 정수 값으로)를 반환함
2) LAST 함수는 특정 조건내에서 마지막 이벤트를 검색하는 데 사용

78. C > A,B
• 싱크 변환을 활용한 조건부 분할 변환

79. 2-3-6
2) true는 일치하는 모든 조건에서 분할하지만 false는 첫번째 일치 조건에서만 분할됨 

80. 6-3-4-5-7 > 1-6-8-4-2
마운트 > 데이터 프레임을 읽기 > 프레임 변환 > 임시 폴더 지정 > 테이블에 결과 쓰기

81. 3-1
1) 지연 매개변수를 사용하려면 'Tumbling window'를 선택
2) Recurrence(30분),Delay(2분)
☞ Delay 창은 데이터 처리 시작을 지연하는 시간, 파이프라인 실행은 예상 실행 시간에 지연 시간을 더한 후에 시작되며 새 실행을 트리거 하기 전에 트리거가 기한을 초과하여 기다리는 시간을 정의함 

82. 3-1-2 > 1-4-3
https://docs.microsoft.com/ko-kr/azure/stream-analytics/stream-analytics-real-time-fraud-detection
• 데이터를 생성하여 Azure Event Hub로 보냄(input)
☞ Steam Analytics 작업을 생성 ☞ 작업 입력 및 출력을 구성 ☞ 데이터를 필터링하는 쿼리를 정의 ☞ Power BI에서 결과를 시각화(Output)

83. 5-4-2 ***

84. C > A
• IR(Intergration Runtime), 통합런타임은 서로 다른 네트워크 환경간에 데이터 통합 기능을 제공하기 위해 Azure Data Factory 및 Azure Synapse 파이프라인에서 사용하는 컴퓨팅 인프라임
• 프라이빗 네트워크에서 데이터 이동은 Azure IR만 가진 특징
 

85. 1-1-2 (적절치 못한 솔루션)
1~2) 스트림 데이터 
3) 참조(reference)데이터는 본질적으로 정적이거나 천천히 변화하는 유한 데이터 세트로, 조회를 수행하거나 데이터 스트림을 보강하는데 사용

86. B
• 텀블링 창 기능은 데이터 스트림을 별개의 시간 세그먼트로 분할하고 이에 대해 기능을 수행하는데 사용되며 텀블링 창의 주요 차별화 요소는 반복되고 겹치지 않으며 이벤트가 둘 이상의 텀블링 창에 속할 수 없다는 것임.

87. 1-1
1) LAG 분석 연산자를 사용하면 특정 제약 조건 내에서 Event Stream에서 이전 이벤트를 조회할 수 있고 변수의 성장 속도를 계산하고 변수가 임계값을 넘을 때 또는 조건이 참이 되기 시작하거나 멈출 때를 감지하는 데 매우 유용함
2) 센서당 성장률 계산 > Limit Duration

88. D
• 이벤트 기반 아키텍처는 생성, 감지, 소비, 이벤트에 대한 반응을 포함하는 일반적인 데이터 통합 패턴으로 데이터 통합 시나리오에서는 Data Factory 고객이 Azure Blob Storage 계정의 파일 도착 또는 삭제와 같이 스토리지 계정에서 발생하는 이벤트를 기반으로 파이프라인을 트리거해야 하는 경우가 많음

89. C
• Azure Data Factory에서 CI/CD(지속적 통합/전달)는 Data Factory 파이프라인을 한 환경(개발,테스트,프로덕
션)에서 다른 환경으로 이동하는 것을 의미함.

90. D > B
• Stream Analytics는 Azure Blob 스토리지와 Azure SQL DB를 참조 데이터의 스토리지 계층으로 지원함

91. C
구매자가 이전 15분 동안 계산하기 때문에 5분 간격으로 계산됨. > 호핑창

92. 4-4-1 > 4-4-3
1) 실시간 스트림 분석
2) ‘No Window’는 분당 500번 실행, ‘Tumbling Window’는 분당 4번 실행하여 더 비용효율적임

93. A > B
• Databricks ABS-AQS 커넥터는 AQS(Azure Queue Storage)를 사용하여 모든 파일을 반복적으로 나열하지 않고도 ABS(Azure Blob Storage) 컨테이너에 작성된 새 파일을 찾을 수 있는 최적화된 파일 원본을 제공함
☞ 해당 기능은 낮은 대기시간, 비용절감의 이점을 가져올 수 있음
A : DataTime 필드에 의한 파티션 각 파티션은 파일을 생성하여 로딩 대기 시간은 줄어들 수 있지만 다른 파티션에 대해 더 많은 폴더와 파일을 생성하기 때문에 저장 비용이 증가할 것임

94. 3-1 > 1-2  ***
1) 고가용성 사용 : 거짓 


95. C > B
• 요구 사항을 조정하려면 최적화된 자동 크기 조정을 사용해야함
☞ 자동화된 클러스터는 항상 최덕화된 자동확장을 사용하며 다목적 클러스터에서 수행되는 자동 크기 조정 유형은 작업 공간 구성에 따라 다름
• 표준 자동크기 조정은 표준 가격 책졍 계층의 작업 영역에 있는 다목적 클러스터에서 사용되지만 최적화된 자동 크기 조정은 Azure Databricks 프리미엄 플랜의 다목적 클러스터에서 사용됨.

96. A
• 텀블링창은 고정된 크기의 중첩되지 않는 연속적인 시간 간격을 의미함
97. B

98. B > D
• 호핑 윈도우 기능은 정해진 시간만큼 앞으로 홉핑함

99. 2-3
1) 게시 분기(publish_brunch는 게시 관련 ARM 템플릿이 저장/업데이트되는 저장소의 분기로 기본적으로 adf_publish
2) RepoName(dwh_batchetl)가 코드 repo의 이름으로 프로젝트 성장에 따라 소스 코드를 관리하기 위한 Git 리포지토리가 포함되어 있음

100. 2-4 > 4-4
1) system.timestamp()
2) 텀블링 창 기능은 데이터 스트림을 별개의 시간 세그먼트로 분할하고 기능을 수행하는데 사용됨
☞ 텀블링 창의 주요 차별화 요소는 반복되고 겹치지 않으며 이벤트가 둘 이상의 텀블링 창에 속할 수 없다는 것임
